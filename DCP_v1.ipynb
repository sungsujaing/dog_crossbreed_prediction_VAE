{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Lambda,Input,Dense,Flatten,Conv2D,Conv2DTranspose\n",
    "from keras.layers import Activation,BatchNormalization,Reshape\n",
    "from keras.models import Model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "original_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking dataset\n",
    "[***Source: Standford Dogs dataset***](http://vision.stanford.edu/aditya86/ImageNetDogs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data')\n",
    "print('number of breeds: {}'.format(len(os.listdir())))\n",
    "total_num = 0\n",
    "for breed in os.listdir():\n",
    "    os.chdir(breed)\n",
    "    total_num += len(os.listdir())\n",
    "    os.chdir('..')\n",
    "print('total number of img: {}'.format(total_num))\n",
    "os.chdir(original_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder/file name cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_cleaning(flag=False):\n",
    "    if flag:\n",
    "        os.chdir('data') # root data folder\n",
    "        for breed in os.listdir():\n",
    "            if os.path.isdir(breed):\n",
    "                os.rename(breed,breed.split('-')[1]) ## cleaning up folder names\n",
    "        for breed in os.listdir(): \n",
    "            os.chdir(breed)\n",
    "            current_list = os.listdir(os.getcwd())\n",
    "            for i in range(len(os.listdir())):\n",
    "                original_name = current_list[i]\n",
    "                new_name = breed + '_{:04d}'.format(i+1) + os.path.splitext(original_name)[-1] ## cleaning up file names\n",
    "                if not os.path.exists(new_name):\n",
    "                    os.rename(original_name,new_name)\n",
    "            os.chdir('..')\n",
    "        os.chdir(original_path)\n",
    "    else:\n",
    "        print('Folder and file names are already processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_cleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "n_samples = 5\n",
    "n_breed = 5\n",
    "fig, rows = plt.subplots(n_breed, n_samples, figsize = (4*n_samples, 3*n_breed))\n",
    "\n",
    "os.chdir('data')\n",
    "for row,breed in zip(rows,np.random.choice(os.listdir(),n_breed,replace=False)):\n",
    "    row[int(np.floor(n_samples/2))].set_title(breed,fontsize=25)\n",
    "    os.chdir(breed)\n",
    "    for col_ax,img in zip(row,np.random.choice(os.listdir(),n_samples,replace=False)):\n",
    "        rand_img = cv2.imread(img)\n",
    "        rand_img = cv2.cvtColor(rand_img,cv2.COLOR_BGR2RGB)\n",
    "        col_ax.imshow(rand_img)\n",
    "        col_ax.axis('off')\n",
    "    os.chdir('..')\n",
    "plt.subplots_adjust(left=0.2, wspace=0.02)\n",
    "os.chdir(original_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/pre-processing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data')\n",
    "breed_list = os.listdir()\n",
    "idx_list = list(range(len(os.listdir())))\n",
    "label_dict = {k: v for k, v in zip(breed_list,idx_list)} \n",
    "os.chdir(original_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 224\n",
    "img_cols = 224\n",
    "img_list = []\n",
    "label_list = []\n",
    "os.chdir('data')\n",
    "for breed in os.listdir():\n",
    "    os.chdir(breed)\n",
    "    current_list = os.listdir()\n",
    "    for img in current_list:\n",
    "        img_in = cv2.imread(img)    \n",
    "        img_in = cv2.cvtColor(img_in,cv2.COLOR_BGR2RGB)    \n",
    "        img_in = cv2.resize(img_in,(img_rows,img_cols),cv2.INTER_AREA)\n",
    "        img_list.append(img_in)\n",
    "        label_list.append(label_dict[breed])\n",
    "    os.chdir('..')\n",
    "os.chdir(original_path)\n",
    "\n",
    "img_data = np.array(img_list).astype(np.float32)\n",
    "img_label = np.array(label_list)\n",
    "img_data /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training data shape: {}'.format(img_data.shape))\n",
    "print('label shape: {}'.format(img_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_shuffled, y_shuffled = shuffle(img_data,img_label,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_shuffled,y_shuffled,test_size=0.2,random_state=0,stratify=y_shuffled)\n",
    "X_train = X_train[:10000]\n",
    "X_valid = X_valid[:1000]\n",
    "y_train = y_train[:10000]\n",
    "y_valid = y_valid[:1000]\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_valid shape: {}'.format(X_valid.shape))\n",
    "print('y_valid shape: {}'.format(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(arg):\n",
    "    arg = [z_mean,z_log_var]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], dim),mean=0.0, stddev=1.0) # reparameterization trick\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = X_train.shape[1]\n",
    "img_cols = X_train.shape[2]\n",
    "channel = X_train.shape[3]\n",
    "input_shape = (img_rows,img_cols,channel)\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(16,3,strides=2,padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32,3,strides=1,padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64,3,strides=2,padding='same',activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "before_flatten_shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(inputs, [z_mean,z_log_var,z])\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "x = Dense(32, activation='relu')(latent_inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(before_flatten_shape[1]*before_flatten_shape[2]*before_flatten_shape[3], activation='relu')(x)\n",
    "x = Reshape((before_flatten_shape[1],before_flatten_shape[2],before_flatten_shape[3]))(x)\n",
    "x = Conv2DTranspose(64,3,strides=2,padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2DTranspose(32,3,activation='relu',strides=1,padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2DTranspose(16,3,activation='relu',strides=2,padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "outputs = Conv2DTranspose(1,3,activation='sigmoid',padding='same')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1 # 1 --> regular VAE\n",
    "# reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "reconstruction_loss = binary_crossentropy(K.flatten(inputs),K.flatten(outputs))\n",
    "reconstruction_loss *= img_rows * img_cols\n",
    "\n",
    "kl_loss = -0.5 * K.sum(beta*(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)), axis=-1)\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEpochPrint(Callback):\n",
    "    def __init__(self, display_step):\n",
    "        self.epoch = 0\n",
    "        self.display_step = display_step\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        self.epoch += 1        \n",
    "        if self.epoch == 1 or self.epoch % self.display_step == 0:\n",
    "            print('Epoch: {}/{} ..... {}: {:.4f} - {}: {:.4f}'.format(self.epoch,\n",
    "                                                                      self.params['epochs'],\n",
    "                                                                      self.params['metrics'][0], \n",
    "                                                                      logs.get(self.params['metrics'][0]),\n",
    "                                                                      self.params['metrics'][1],               \n",
    "                                                                      logs.get(self.params['metrics'][1])))\n",
    "NEpochPrinter = NEpochPrint(display_step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_or_load_weights(flag):\n",
    "    if flag == 'train':\n",
    "        hist = vae.fit_generator(datagen.flow(X_train,batch_size=batch_size),\n",
    "                                 steps_per_epoch = len(X_train)//batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 validation_data=(X_valid, None),\n",
    "                                 verbose=0,\n",
    "                                 callbacks=[NEpochPrinter])\n",
    "        vae.save_weights('dcp_v1.h5')\n",
    "        return hist\n",
    "    if flag == 'load':\n",
    "        vae.load_weights('dcp_v1.h5') # load all the weights for encoder and decoder when loading for vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = train_or_load_weights(flag='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
