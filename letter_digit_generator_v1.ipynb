{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda,Input,Dense,Flatten,Conv2D,Conv2DTranspose\n",
    "from keras.layers import Activation,BatchNormalization,Reshape,Concatenate,Dropout\n",
    "from keras.models import Model\n",
    "from keras.datasets import fashion_mnist,mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.callbacks import Callback,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "from mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emndata = MNIST('emnist_data')\n",
    "rows = 28\n",
    "cols = 28\n",
    "\n",
    "X_train,y_train = emndata.load('emnist_data/emnist-byclass-train-images-idx3-ubyte',\n",
    "                               'emnist_data/emnist-byclass-train-labels-idx1-ubyte')\n",
    "X_test,y_test = emndata.load('emnist_data/emnist-byclass-test-images-idx3-ubyte',\n",
    "                             'emnist_data/emnist-byclass-test-labels-idx1-ubyte')\n",
    "X_train = np.array(X_train)\n",
    "X_train = X_train.reshape(X_train.shape[0],rows,cols)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.reshape(X_test.shape[0],rows,cols)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_train.shape[0]):\n",
    "    X_train[i]=np.transpose(X_train[i])\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test[i]=np.transpose(X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Class: This represents the most useful organization\n",
    "from a classification perspective as it contains the segmented digits and characters arranged by class. There are\n",
    "62 classes comprising [0-9], [a-z] and [A-Z]. The data is\n",
    "also split into a suggested training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_str = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "lebel_dict = {i:v for i,v in enumerate(label_str)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "n_samples = 5\n",
    "n_cls = 5\n",
    "n_label = len(np.unique(y_train))\n",
    "fig, rows = plt.subplots(n_cls,n_samples,figsize=(4*n_samples,3*n_cls))\n",
    "\n",
    "for row,cls in zip(rows,np.random.choice(list(range(n_label)),n_cls)):\n",
    "    row[int(np.floor(n_samples/2))].set_title(lebel_dict[cls],fontsize=25)\n",
    "    for col_ax,img_idx in zip(row,[i for i,v in enumerate(y_train) if v==cls][:n_samples]):\n",
    "        img = X_train[img_idx]\n",
    "        col_ax.imshow(img,cmap='gray')\n",
    "        col_ax.axis('off')\n",
    "plt.subplots_adjust(left=0.2, wspace=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = list(map(lambda x:lebel_dict[x], y_train))\n",
    "# y_test = list(map(lambda x:lebel_dict[x], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/(255/2)-1 # for tanh\n",
    "X_test = X_test.astype('float32')/(255/2)-1\n",
    "X_train = np.expand_dims(X_train,-1)\n",
    "X_test =  np.expand_dims(X_test,-1)\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,n_label)\n",
    "y_test = to_categorical(y_test,n_label)\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(arg):\n",
    "    arg = [z_mean,z_log_var]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], dim),mean=0.0, stddev=1.0) # reparameterization trick\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 1\n",
    "img_rows = X_train.shape[1]\n",
    "img_cols = X_train.shape[2]\n",
    "input_shape = (img_rows,img_cols,channel)\n",
    "batch_size = 128\n",
    "latent_dim = 10\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',patience=10,verbose=1,factor=0.5,min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = initializers.random_normal(stddev=0.02)\n",
    "gamma_init = initializers.random_normal(mean=1.0,stddev=0.02)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(16,3,strides=1,padding='same',kernel_initializer=w_init)(inputs)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32,3,strides=1,padding='same',kernel_initializer=w_init)(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64,3,strides=2,padding='same',kernel_initializer=w_init)(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init)(x)\n",
    "x = Activation('relu')(x)\n",
    "before_flatten_shape = K.int_shape(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128,kernel_initializer=w_init,activation='relu')(x)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(inputs, [z_mean,z_log_var,z])\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "label_inputs = Input(shape=(n_label,),name='label')\n",
    "x = Concatenate()([latent_inputs,label_inputs])\n",
    "\n",
    "x = Dense(128,kernel_initializer=w_init,activation='relu')(x)\n",
    "x = Dense(before_flatten_shape[1]*before_flatten_shape[2]*before_flatten_shape[3],activation='relu',kernel_initializer=w_init)(x)\n",
    "x = Reshape((before_flatten_shape[1],before_flatten_shape[2],before_flatten_shape[3]))(x)\n",
    "\n",
    "x = Conv2DTranspose(64,3,strides=1,padding='same',kernel_initializer=w_init)(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2DTranspose(32,3,strides=2,padding='same',kernel_initializer=w_init)(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2DTranspose(16,3,strides=1,padding='same',kernel_initializer=w_init)(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "outputs = Conv2DTranspose(channel,3,activation='tanh',padding='same',kernel_initializer=w_init)(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model([latent_inputs,label_inputs],outputs)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = decoder([encoder(inputs)[2],label_inputs])\n",
    "vae = Model([inputs,label_inputs], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1 # 1 --> regular VAE\n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "# reconstruction_loss = binary_crossentropy(K.flatten(inputs),K.flatten(outputs))\n",
    "reconstruction_loss *= img_rows*img_cols\n",
    "\n",
    "kl_loss = -0.5*beta*K.sum(1+z_log_var-K.square(z_mean)-K.exp(z_log_var),axis=-1)\n",
    "vae_loss = K.mean(reconstruction_loss+kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('best_weight_ldg_v1',exist_ok=True)\n",
    "best_model_weight_path = os.path.join('best_weight_ldg_v1','ldg_v1'+'-best-wiehgts'+'-{epoch:03d}-{loss:.3f}-{val_loss:.3f}.h5')\n",
    "save_best_model = ModelCheckpoint(best_model_weight_path,monitor='val_loss',verbose=0,save_weights_only=True,save_best_only=True,mode='min')\n",
    "\n",
    "class NEpochPrint(Callback):\n",
    "    def __init__(self, display_step):\n",
    "        self.epoch = 0\n",
    "        self.display_step = display_step\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        self.epoch += 1        \n",
    "        if self.epoch == 1 or self.epoch % self.display_step == 0:\n",
    "            print('Epoch: {}/{} ..... {}: {:.4f} - {}: {:.4f}'.format(self.epoch,\n",
    "                                                                      self.params['epochs'],\n",
    "                                                                      self.params['metrics'][0], \n",
    "                                                                      logs.get(self.params['metrics'][0]),\n",
    "                                                                      self.params['metrics'][1],               \n",
    "                                                                      logs.get(self.params['metrics'][1])))\n",
    "NEpochPrinter = NEpochPrint(display_step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_or_load_weights(flag,weight_name=None):\n",
    "    if flag == 'train':\n",
    "        hist = vae.fit([X_train,y_train],\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       validation_data=([X_test,y_test],None),\n",
    "                       verbose=1,\n",
    "                       callbacks=[save_best_model,learning_rate_reduction,NEpochPrinter])\n",
    "        vae.save_weights('ldg_weight.h5')\n",
    "        return hist\n",
    "    if flag == 'load':\n",
    "        vae.load_weights(os.path.join('best_weight_ldg_v1',weight_name)) # load all the weights for encoder and decoder when loading for vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer=Adam(lr=learning_rate))\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = train_or_load_weights(flag='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_plot(hist,model_name):\n",
    "    loss = [hist.history['loss'],hist.history['val_loss']]\n",
    "    plt.plot(loss[0],color='b',label='training')\n",
    "    plt.plot(loss[1],color='r',label='valid')\n",
    "    plt.title(model_name,fontsize=18)\n",
    "    plt.legend(loc='best',fontsize=13)\n",
    "    plt.xlabel('epoch',fontsize=15)\n",
    "    plt.ylabel('')\n",
    "    plt.tick_params(axis='both',labelsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_plot(hist,'ldg_v1 training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_five_reconstruction(input_set,random_idx,encoder,decoder):\n",
    "    fig, axes = plt.subplots(2,5,figsize=(15,5))\n",
    "    for row,flag in zip(axes,['in_img','out_img']): \n",
    "        for col,idx in zip(row,random_idx):\n",
    "            original = input_set[idx]\n",
    "            if flag == 'in_img':\n",
    "                original_digit = original.reshape(img_rows,img_cols)\n",
    "                col.imshow(original_digit,cmap='bone')\n",
    "                col.set_title('original, idx={}'.format(idx))\n",
    "            if flag == 'out_img':\n",
    "                encoded_z = encoder.predict(np.expand_dims(original,0),batch_size=1)[2]\n",
    "                predict = decoder.predict(encoded_z)\n",
    "                decoded_digit = predict.reshape(img_rows,img_cols)\n",
    "                col.imshow(decoded_digit,cmap='bone')\n",
    "                col.set_title('reconstructed, idx={}'.format(idx))\n",
    "            col.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traing set reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "random_idx = np.random.randint(len(X_train),size=5)\n",
    "plot_five_reconstruction(X_train,random_idx,encoder,decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "random_idx = np.random.randint(len(X_test),size=5)\n",
    "plot_five_reconstruction(X_test,random_idx,encoder,decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_encoded = encoder.predict(X_test, batch_size=1)[2]\n",
    "# latent_space_df = pd.DataFrame(X_test_encoded,columns=['vector1','vector2'])\n",
    "# latent_space_df['label'] = y_test\n",
    "# latent_space_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_context('paper', font_scale=1.5)\n",
    "# sns.set_style('white')\n",
    "# plt.figure()\n",
    "# sns.lmplot('vector1','vector2',data=latent_space_df,hue='label',fit_reg=False,scatter_kws={'alpha':0.6,\"s\": 40},\n",
    "#             height=8,palette=sns.color_palette(\"hls\",latent_space_df['label'].nunique()))\n",
    "# plt.title('Latent space by class')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 30\n",
    "# digit_size = 28\n",
    "# figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "# grid_x = np.linspace(-4, 4, n)\n",
    "# grid_y = np.linspace(-4, 4, n)\n",
    "\n",
    "# for i, yi in enumerate(grid_x):\n",
    "#     for j, xi in enumerate(grid_y):\n",
    "#         z_sample = np.array([[xi, yi]])\n",
    "#         x_decoded = decoder.predict(z_sample)\n",
    "#         digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "#         figure[i * digit_size: (i + 1) * digit_size,\n",
    "#                j * digit_size: (j + 1) * digit_size] = digit\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(figure,cmap='bone')\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(img1,img2,step,encoder,decoder,plot=True):\n",
    "    img1_encoded_z = encoder.predict(np.expand_dims(img1,0),batch_size=1)[2]\n",
    "#     print('1: {}'.format(img1_encoded_z))   \n",
    "    img2_encoded_z = encoder.predict(np.expand_dims(img2,0),batch_size=1)[2]\n",
    "#     print('2: {}'.format(img2_encoded_z))\n",
    "    step_size = (img2_encoded_z-img1_encoded_z)/step\n",
    "#     print('step: {}'.format(step_size))\n",
    "\n",
    "    step_list = [img1_encoded_z]\n",
    "    for _ in range(step):\n",
    "        img1_encoded_z = img1_encoded_z + step_size\n",
    "        step_list.append(img1_encoded_z)\n",
    "    if plot:\n",
    "        os.makedirs('interpolation_images',exist_ok=True)\n",
    "        fig,axes = plt.subplots(int(np.ceil((step+1)/5)),5, figsize=(5*4, int(np.ceil((step+1)/5))*4))\n",
    "        for i,(ax,vector) in enumerate(zip(axes.flatten(),step_list)):\n",
    "            predict = decoder.predict(vector).reshape(img_rows,img_cols)\n",
    "            ax.imshow(predict,cmap='bone')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            fig_indi,ax_indi = plt.subplots(figsize=(5,5))\n",
    "            ax_indi.imshow(predict,cmap='bone')\n",
    "            ax_indi.axis('off')\n",
    "            plt.title('step {}/{}'.format(i,step),fontsize=24,fontweight='bold')\n",
    "            fig_indi.savefig('interpolation_images/step_{}.png'.format(i))\n",
    "            plt.close()\n",
    "            if i == 0:\n",
    "                ax.set_title('From Image 1\\n0%',fontsize=24,fontweight='bold')\n",
    "            elif i == step:\n",
    "                ax.set_title('To Image 2\\n100%',fontsize=24,fontweight='bold')\n",
    "            else:\n",
    "                ax.set_title('step {}/{}\\n{:.0f}%'.format(i,step,i*100/step),fontsize=24,fontweight='bold')\n",
    "        plt.subplots_adjust(hspace=0.3,left=0.1, wspace=0.02)\n",
    "        if (step+1)%5 != 0:\n",
    "            for i in axes.flatten()[(step+1)-len(axes.flatten()):]:\n",
    "                i.set_visible(False)\n",
    "        fig.savefig('interpolation_images/summary.png')\n",
    "    return step_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(150)\n",
    "random_idx_2 = np.random.randint(len(X_test),size=2)\n",
    "print(random_idx_2)\n",
    "_ = interpolation(X_test[random_idx_2[0]],X_test[random_idx_2[1]],10,encoder,decoder,plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
